{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e341a3",
   "metadata": {},
   "source": [
    "## Q1. In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905181cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\tanji\\Desktop\\myPW\\assignments\\datasets\\Bengaluru_House_Data.csv')\n",
    "\n",
    "def find_outliers_iqr(data, columns):  #number of outliers\n",
    "    outliers = []\n",
    "    for column in columns:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        column_outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "        outliers.append(column_outliers)\n",
    "    return pd.concat(outliers)\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['number'])\n",
    "outliers_df = find_outliers_iqr(df, numeric_columns)\n",
    "print(len(outliers_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61a91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_type          0\n",
       "availability       0\n",
       "location           1\n",
       "size              16\n",
       "society         5502\n",
       "total_sqft         0\n",
       "bath              73\n",
       "balcony          609\n",
       "price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4aa79",
   "metadata": {},
   "source": [
    "Since we have 2315 outliers and  more than 5502 missing data, we may choose MSE or RMSE so as to penalize the outliers. We may also use medAE (meadian absolute error to be robust to outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872fcb5",
   "metadata": {},
   "source": [
    "## Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?\n",
    "\n",
    "If your goal is to predict the actual price of a house as accurately as possible, the Mean Squared Error (MSE) would be the more appropriate evaluation metric to use in assessing the performance of your SVM regression model. Here's why:\n",
    "\n",
    "1. **MSE Measures Prediction Accuracy**: MSE directly measures the accuracy of your predictions by calculating the average of the squared differences between your predicted prices and the actual prices of houses. Lower MSE values indicate better accuracy.\n",
    "\n",
    "2. **Prediction Accuracy is the Primary Goal**: When your primary objective is to predict house prices as accurately as possible, you want to minimize the errors in your predictions. MSE penalizes larger errors more heavily, which is crucial in this context because even a small prediction error in house prices can have a significant impact.\n",
    "\n",
    "3. **R-squared Emphasizes Explained Variance**: While R-squared (R²) is a valuable metric for understanding the proportion of variance explained by your model, it is not primarily focused on prediction accuracy. R² measures how well the model fits the data in terms of explaining the variance, but it may not penalize larger prediction errors as heavily as MSE does.\n",
    "\n",
    "4. **Interpretability**: MSE has a direct and interpretable scale because it is in the same units as your target variable (e.g., dollars in the case of house prices). This makes it easy to understand the magnitude of the prediction errors.\n",
    "\n",
    "If your primary goal is to predict house prices as accurately as possible, prioritize the use of Mean Squared Error (MSE) as your evaluation metric. Minimizing MSE implies minimizing prediction errors, which is essential in real estate or any application where precise predictions are crucial. However, it's also a good practice to complement MSE with other metrics like R-squared (R²) to gain a more comprehensive understanding of your model's performance, especially in terms of explaining variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f20300",
   "metadata": {},
   "source": [
    "## Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
    "\n",
    "When you have a dataset with a significant number of outliers, it's important to choose a regression metric that is robust to outliers and does not overly penalize the model for those outliers. The most appropriate regression metric in this scenario is the **Median Absolute Error (MedAE)**.\n",
    "\n",
    "Here's why the Median Absolute Error is a good choice for datasets with outliers:\n",
    "\n",
    "1. **Robustness to Outliers**: Unlike metrics like Mean Squared Error (MSE) or Root Mean Squared Error (RMSE), which can be heavily influenced by outliers due to the squaring of errors, MedAE is based on the median of the absolute errors. The median is robust to outliers because it represents the middle value of the data and is less affected by extreme values.\n",
    "\n",
    "2. **Interpretability**: MedAE provides an interpretable metric in the same units as the target variable, making it easy to understand the magnitude of the prediction errors.\n",
    "\n",
    "3. **Resilience**: When you have a significant number of outliers, using metrics like MSE or RMSE can lead to models that are overly conservative and perform poorly on the majority of non-outlier data points. MedAE provides a more balanced assessment of prediction errors.\n",
    "\n",
    "\n",
    "\n",
    "By focusing on the Median Absolute Error, you prioritize assessing the model's performance on the central tendency of the data while being less influenced by the presence of outliers. This is particularly useful when dealing with datasets where outliers may be important but should not dominate the evaluation of the model's overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff114e57",
   "metadata": {},
   "source": [
    "## Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?\n",
    "\n",
    "When RMSE and MSE are close, choosing RMSE is better because it gives the magnitude of the error in the same unit as the outcome variable. Also it penalizes the outlier unlike MAE.\n",
    "\n",
    "- It provides an interpretable metric in the same units as the target variable, similar to MAE but with a different scale.\n",
    "- Like MSE, it penalizes larger errors more heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058fda4",
   "metadata": {},
   "source": [
    "## Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
    "\n",
    "If the goal is to measure how well SVM regression models explain the variance in the target variable, the most appropriate evaluation metric is the **R-squared (R²)** or Coefficient of Determination. R² provides a measure of the proportion of the variance in the target variable that is explained by the independent variables or predictors in your model. \n",
    "\n",
    "Here's why R² is suitable for this purpose:\n",
    "\n",
    "1. **Variance Explained**: R² quantifies the fraction of the total variance in the target variable that is accounted for by the model. A higher R² value indicates that the model explains a larger portion of the variance, which is desirable when you want to understand how well your model captures the underlying patterns in the data.\n",
    "\n",
    "2. **Interpretability**: R² values range between 0 and 1, where 0 means the model does not explain any variance, and 1 means the model explains all the variance. This makes it easy to interpret and compare the explanatory power of different models. Higher R² values are indicative of better explanatory models.\n",
    "\n",
    "3. **Model Selection**: When comparing SVM regression models with different kernels (linear, polynomial, RBF), R² allows you to assess how well each kernel type captures the variance in the target variable. It helps you choose the kernel that provides the best balance between underfitting and overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
