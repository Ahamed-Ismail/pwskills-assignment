{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efa86cb",
   "metadata": {},
   "source": [
    "## Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical test used to compare the means of two or more groups to determine if there are any statistically significant differences between them. To perform ANOVA, certain assumptions need to be met for the results to be valid. These assumptions are:\n",
    "\n",
    "1. Independence: The observations within each group must be independent of each other. This means that the value of one observation should not be related to the value of another observation within the same group.\n",
    "\n",
    "2. Normality: The data in each group should be normally distributed. In other words, the data points within each group should follow a bell-shaped curve when plotted on a histogram or a Q-Q plot.\n",
    "\n",
    "3. Homogeneity of Variance: The variances of the groups being compared should be approximately equal. This assumption is also known as homoscedasticity. It means that the spread or dispersion of data points around the group means should be similar for all groups.\n",
    "\n",
    "4. Random Sampling: The data should be collected using random sampling techniques to ensure that the groups are representative of the population they are drawn from.\n",
    "\n",
    "\n",
    "When ANOVA assumptions are violated, researchers have several options to address the issue:\n",
    "\n",
    "a. Transformation: If the data violates the normality assumption, applying a suitable transformation (e.g., log transformation) may make it conform to the assumption.\n",
    "\n",
    "b. Non-parametric tests: If normality and homogeneity of variance assumptions are severely violated, non-parametric tests (e.g., Kruskal-Wallis test) can be used instead of ANOVA.\n",
    "\n",
    "c. Robust ANOVA: Some ANOVA methods can handle violations of assumptions to a certain extent (e.g., Welch's ANOVA for unequal variances).\n",
    "\n",
    "d. Data exclusion: In extreme cases, researchers may choose to exclude or modify problematic data points or groups after carefully considering the impact of such decisions on the validity of the analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc3cf9",
   "metadata": {},
   "source": [
    "## Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-Way ANOVA (One-Factor ANOVA):\n",
    "   One-Way ANOVA is used when there is one independent variable (factor) with three or more levels (groups). The goal of One-Way ANOVA is to determine if there are any statistically significant differences between the means of the groups. It is appropriate when we have one categorical independent variable and a continuous dependent variable. For example, a One-Way ANOVA can be used to compare the average test scores of students from different schools or to compare the average yields of crops from different fertilizer treatments.\n",
    "\n",
    "2. Two-Way ANOVA (Two-Factor ANOVA):\n",
    "   Two-Way ANOVA is used when there are two independent variables (factors) with multiple levels, and we want to examine how these variables interact to influence the dependent variable. The factors can be either categorical or continuous variables. Two-Way ANOVA allows us to investigate main effects (the effect of each factor individually) as well as interaction effects (how the combination of factors influences the dependent variable). For example, a Two-Way ANOVA can be used to study the effects of different teaching methods (factor 1) and gender (factor 2) on exam scores.\n",
    "\n",
    "3. Repeated Measures ANOVA (Within-Subjects ANOVA):\n",
    "   Repeated Measures ANOVA is used when the same group of participants is measured under multiple conditions or time points. This type of ANOVA is suitable for situations where the data points are not independent, such as when participants are measured before and after an intervention or when the same individuals are exposed to different treatments. Repeated Measures ANOVA is useful for studying changes over time or comparing the effects of different treatments within the same subjects. For example, a Repeated Measures ANOVA can be used to analyze the effects of different exercises on participants' heart rates, with heart rate measurements taken at various time points during the exercise session.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16e18c",
   "metadata": {},
   "source": [
    "## Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "The partitioning of variance in ANOVA refers to the process of dividing the total variance observed in the data into different components, each representing a different source of variability. Understanding this concept is crucial because it allows us to understand how much of the total variance in the data can be attributed to different factors or sources, and it helps us in determining whether those factors have a statistically significant effect on the dependent variable.\n",
    "\n",
    "In ANOVA, the total variance in the data is partitioned into three main components:\n",
    "\n",
    "1. Between-Groups Variance (Treatment Variance): This component represents the variance in the dependent variable that is due to differences between the group means. It measures the variation among the means of the different groups being compared. If this variance is large compared to the within-group variance, it suggests that there are significant differences between the groups.\n",
    "\n",
    "2. Within-Groups Variance (Error Variance): This component represents the variance in the dependent variable that is due to individual differences within each group or experimental condition. It measures the variation of individual data points around their respective group means. If this variance is small compared to the between-groups variance, it suggests that the group means are significantly different from each other.\n",
    "\n",
    "3. Total Variance: This is the overall variance observed in the data, and it is the sum of the between-groups variance and the within-groups variance.\n",
    "\n",
    "The ratio of the between-groups variance to the within-groups variance is used to calculate the F-statistic, which is the test statistic used in ANOVA. The F-statistic is then compared to critical values from the F-distribution to determine whether there are significant differences between the group means.\n",
    "\n",
    "Importance of Understanding the Partitioning of Variance in ANOVA:\n",
    "\n",
    "1. Identifying Significant Effects: By understanding the partitioning of variance, researchers can determine if there are statistically significant differences between the groups being compared. This information is valuable in assessing the impact of different factors on the dependent variable.\n",
    "\n",
    "2. Interpreting Results: Partitioning of variance helps in interpreting the results of ANOVA. It allows researchers to understand the relative importance of different sources of variability and to draw meaningful conclusions about the effects of the independent variables.\n",
    "\n",
    "3. Evaluating Model Fit: Understanding how variance is partitioned helps in assessing the fit of the ANOVA model to the data. It allows researchers to assess whether the model captures the underlying patterns and variability adequately.\n",
    "\n",
    "4. Designing Experiments: Knowledge of partitioning of variance is crucial for designing experiments effectively. It helps in determining the appropriate sample size and study design to detect significant effects reliably.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29875e3f",
   "metadata": {},
   "source": [
    "## Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "In a one-way ANOVA, the Total Sum of Squares (SST) measures the total variability in the data, the Explained Sum of Squares (SSE) measures the variability explained by the group means, and the Residual Sum of Squares (SSR) measures the unexplained variability or error in the model.\n",
    "\n",
    "To calculate these sums of squares in Python, you can use the following steps:\n",
    "\n",
    "1. Calculate the Total Sum of Squares (SST):\n",
    "   SST is the sum of the squared differences between each data point and the overall mean of the data. It measures the total variability in the dependent variable.\n",
    "\n",
    "2. Calculate the Explained Sum of Squares (SSE):\n",
    "   SSE is the sum of the squared differences between each group mean and the overall mean of the data, weighted by the number of data points in each group. It measures the variability explained by the group means.\n",
    "\n",
    "3. Calculate the Residual Sum of Squares (SSR):\n",
    "   SSR is the sum of the squared differences between each data point and its respective group mean. It measures the unexplained variability or error in the model.\n",
    "\n",
    "Let's assume you have the data for the one-way ANOVA in a Pandas DataFrame called `df`, with the dependent variable in the column 'dependent_var' and the grouping variable (categorical) in the column 'group_var'.\n",
    "\n",
    "Here's how you can calculate the SST, SSE, and SSR using Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the data in a DataFrame called 'df'\n",
    "# 'dependent_var' is the column containing the dependent variable\n",
    "# 'group_var' is the column containing the grouping variable\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = df['dependent_var'].mean()\n",
    "\n",
    "# Calculate the Total Sum of Squares (SST)\n",
    "SST = np.sum((df['dependent_var'] - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the group means\n",
    "group_means = df.groupby('group_var')['dependent_var'].mean()\n",
    "\n",
    "# Calculate the number of data points in each group\n",
    "group_counts = df['group_var'].value_counts()\n",
    "\n",
    "# Calculate the Explained Sum of Squares (SSE)\n",
    "SSE = np.sum(group_counts * (group_means - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the Residual Sum of Squares (SSR)\n",
    "residuals = df['dependent_var'] - df['group_var'].map(group_means)\n",
    "SSR = np.sum(residuals ** 2)\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3cbe4",
   "metadata": {},
   "source": [
    "## Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "\n",
    "\n",
    "In a two-way ANOVA, you can calculate the main effects and interaction effects using Python by fitting a two-way ANOVA model and then extracting the relevant information from the model's summary or using the sums of squares obtained from the ANOVA table. We can use the `statsmodels` library to perform the two-way ANOVA in Python.\n",
    "\n",
    "Here's an example of how to calculate the main effects and interaction effects using Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Assuming you have the data in a DataFrame called 'df'\n",
    "# 'dependent_var' is the column containing the dependent variable\n",
    "# 'group_var1' and 'group_var2' are the columns containing the two grouping variables\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'dependent_var ~ C(group_var1) + C(group_var2) + C(group_var1):C(group_var2)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract main effects and interaction effects from the ANOVA table\n",
    "main_effect_group1 = anova_table['sum_sq']['C(group_var1)']\n",
    "main_effect_group2 = anova_table['sum_sq']['C(group_var2)']\n",
    "interaction_effect = anova_table['sum_sq']['C(group_var1):C(group_var2)']\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect for Group 1:\", main_effect_group1)\n",
    "print(\"Main Effect for Group 2:\", main_effect_group2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n",
    "```\n",
    "\n",
    "In this code, we first fit the two-way ANOVA model using the `ols` function from `statsmodels.formula.api`. The formula specifies the relationship between the dependent variable and the two grouping variables, as well as the interaction between them.\n",
    "\n",
    "Then, we extract the ANOVA table using `sm.stats.anova_lm`, which contains the sum of squares for each factor and interaction. We use the `['sum_sq']` indexer to access the sum of squares for each term.\n",
    "\n",
    "Finally, we assign the main effects and interaction effects to separate variables for further analysis or interpretation.\n",
    "\n",
    "It's important to note that this example assumes the data is balanced, meaning each combination of levels for the two grouping variables has the same number of observations. If the data is unbalanced, you may need to use different techniques to calculate the effects, such as Type II or Type III sums of squares. Additionally, you may need to consider post-hoc tests to further investigate significant interactions or main effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d6f40",
   "metadata": {},
   "source": [
    "## Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are statistically significant differences between the means of the groups being compared. The p-value associated with the F-statistic indicates the probability of obtaining the observed F-statistic (or more extreme) if the null hypothesis is true. A small p-value (typically less than the chosen significance level, often 0.05) suggests that the observed differences between the group means are unlikely to have occurred by chance alone.\n",
    "\n",
    "In your case, the F-statistic is 5.23, and the p-value is 0.02. Since the p-value is less than 0.05, we can conclude that there are statistically significant differences between the group means.\n",
    "\n",
    "Interpretation of the results:\n",
    "Based on the results of the one-way ANOVA, we have evidence to reject the null hypothesis, which stated that there are no significant differences between the means of the groups. The small p-value (0.02) indicates that the probability of observing such differences between the groups by chance alone is only 2%, assuming the null hypothesis is true. Therefore, we have sufficient evidence to support the alternative hypothesis, which states that there are significant differences between at least two of the group means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2aa7c7",
   "metadata": {},
   "source": [
    "## Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\n",
    "Handling missing data in a repeated measures ANOVA is an important consideration to ensure the validity and accuracy of the analysis. There are several methods to handle missing data, and the choice of method can have potential consequences on the results and conclusions of the analysis. Here are some common approaches to handle missing data:\n",
    "\n",
    "1. Complete Case Analysis (Listwise Deletion):\n",
    "   This method involves removing all cases (participants) with missing data on any variable used in the analysis. While this is a straightforward approach, it may lead to a loss of valuable information, reduced sample size, and potential bias if the missing data are not completely at random (MCAR).\n",
    "\n",
    "2. Pairwise Deletion:\n",
    "   In this approach, each analysis is conducted with only the available data for that particular analysis, even if some participants have missing data on some variables. It maximizes the use of available data but can lead to different sample sizes across analyses, potentially affecting the results.\n",
    "\n",
    "3. Mean Imputation:\n",
    "   Mean imputation involves replacing missing values with the mean value of the observed data for that variable. While this approach preserves the sample size, it can lead to biased estimates of group means and an underestimation of standard errors, resulting in artificially inflated statistical significance.\n",
    "\n",
    "4. Multiple Imputation:\n",
    "   Multiple imputation generates several plausible imputed datasets based on the observed data and their uncertainty. Each dataset is then analyzed separately, and the results are combined to provide more accurate estimates and standard errors. Multiple imputation is considered a more robust approach than mean imputation.\n",
    "\n",
    "Potential Consequences of Different Methods:\n",
    "\n",
    "The choice of method for handling missing data can have several consequences:\n",
    "\n",
    "1. Bias: Complete case analysis and mean imputation can introduce bias into the results, leading to inaccurate estimates of group means and effect sizes.\n",
    "\n",
    "2. Loss of Power: Removing cases with missing data (complete case analysis) or using pairwise deletion can reduce the sample size, which can result in a loss of statistical power to detect significant effects.\n",
    "\n",
    "3. Standard Errors: Improper handling of missing data can lead to underestimation of standard errors, affecting the precision of estimated group differences and confidence intervals.\n",
    "\n",
    "4. Incorrect Inferences: Using different methods for handling missing data can lead to different conclusions about the significance of effects and the overall pattern of results.\n",
    "\n",
    "In summary, handling missing data in a repeated measures ANOVA requires careful consideration, and the choice of method should be based on the nature of the missing data and the assumptions underlying each method. Multiple imputation is generally recommended as a more reliable and valid approach, but the most appropriate method will depend on the specific characteristics of the dataset and the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ad307",
   "metadata": {},
   "source": [
    "## Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "After performing an ANOVA and finding a significant overall effect, post-hoc tests are used to determine which specific group means differ significantly from each other. Post-hoc tests are necessary because ANOVA only tells us that there are differences among the groups, but it does not identify which specific groups are different. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test:\n",
    "   Tukey's HSD test is used when the sample sizes are equal and the assumption of equal variances holds. It controls the family-wise error rate, providing simultaneous confidence intervals for all pairwise comparisons. This test is generally considered conservative, which means it might be less likely to detect small differences.\n",
    "\n",
    "2. Bonferroni correction:\n",
    "   The Bonferroni correction is a simple and conservative method that adjusts the significance level for each pairwise comparison to control the family-wise error rate. It is suitable when performing multiple pairwise comparisons and can be applied regardless of whether the sample sizes are equal or unequal.\n",
    "\n",
    "3. Scheffe's method:\n",
    "   Scheffe's method is a more liberal post-hoc test that can be used when the assumption of equal variances is violated or when sample sizes are unequal. It provides simultaneous confidence intervals for all pairwise comparisons, controlling the family-wise error rate.\n",
    "\n",
    "4. Games-Howell test:\n",
    "   The Games-Howell test is a non-parametric post-hoc test that does not assume equal variances or equal sample sizes. It is more robust than Tukey's HSD or Bonferroni correction when these assumptions are violated.\n",
    "\n",
    "Example of a situation where a post-hoc test might be necessary:\n",
    "\n",
    "Let's say a researcher conducts an experiment to compare the effectiveness of three different drugs (Drug A, Drug B, and Drug C) in reducing pain. The researcher collects pain ratings from participants after administering each drug and conducts a one-way ANOVA to test for differences among the drug groups. The ANOVA results show a significant overall effect.\n",
    "\n",
    "To determine which specific drug groups differ significantly from each other, the researcher needs to perform post-hoc tests. Suppose the researcher uses Tukey's HSD test and finds that Drug A and Drug B have significantly lower pain ratings than Drug C, but there is no significant difference between Drug A and Drug B.\n",
    "\n",
    "In this example, the post-hoc test (Tukey's HSD) was necessary to identify the specific differences between the drug groups. Without the post-hoc test, the researcher would only know that there is a significant overall effect of the drugs on pain ratings, but they would not have been able to determine which drugs are significantly different from each other. Post-hoc tests allow researchers to make more precise and specific comparisons among the groups after a significant ANOVA result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d157af",
   "metadata": {},
   "source": [
    "## Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "H0: To significant difference between mean\n",
    "\n",
    "H1: THere significant difference between mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a4541b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We failed to reject null hypothesis.There is no significant differences between the mean weight loss of the three diets\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "alpha=0.05\n",
    "diet_A = [5, 7, 8, 6, 4, 5, 7, 6, 6, 5, 4, 7, 8, 6, 7, 5, 6, 5, 6, 7, 6, 5, 6, 8, 6, 7, 6, 5, 4, 6, 5, 7, 6, 5, 4, 6, 5, 7, 5, 6, 4, 7, 6, 5, 8, 7, 6, 5, 6, 4]\n",
    "diet_B = [8, 7, 6, 5, 6, 7, 6, 5, 6, 8, 7, 6, 4, 6, 5, 6, 7, 6, 5, 6, 4, 5, 7, 8, 6, 5, 4, 7, 6, 5, 7, 6, 5, 6, 4, 5, 6, 7, 6, 5, 8, 6, 7, 6, 5, 4, 6, 5]\n",
    "diet_C = [7, 6, 5, 6, 4, 5, 7, 6, 5, 6, 8, 6, 7, 6, 5, 6, 4, 7, 6, 5, 6, 5, 6, 7, 5, 6, 4, 6, 5, 7, 5, 6, 4, 6, 5, 7, 6, 5, 8, 7, 6, 5, 6, 4, 7, 6, 5, 6]\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "\n",
    "critical_val=stats.f.ppf(q=1-alpha, dfn=2, dfd=47)  #CI, dfBetween, dfWithin\n",
    "\n",
    "if f_statistic> critical_val or p_value<alpha:\n",
    "    print(\"We reject null hypothesis.T here is significant differences between the mean weight loss of the three diets\")\n",
    "else:\n",
    "    print(\"We failed to reject null hypothesis.There is no significant differences between the mean weight loss of the three diets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed266534",
   "metadata": {},
   "source": [
    "## Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a1c95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 69.61162716207558\n",
      "p-value: 1.8187712093003434e-43\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Replace these lists with your actual completion time data for each program and experience level\n",
    "program_A_novice = [15, 20, 18, 17, 16, 19, 21, 22, 20, 16, 18, 19, 17, 21, 18, 20, 16, 19, 17, 22, 18, 19, 16, 17, 20, 21, 19, 18, 16, 17]\n",
    "program_A_experienced = [12, 10, 14, 11, 13, 9, 11, 13, 10, 12, 14, 13, 11, 12, 10, 9, 11, 13, 12, 10, 11, 13, 14, 12, 9, 11, 10, 13, 12, 14]\n",
    "\n",
    "program_B_novice = [22, 24, 20, 23, 19, 21, 20, 24, 22, 21, 23, 19, 24, 20, 22, 19, 23, 21, 20, 24, 22, 21, 19, 20, 23, 24, 21, 22, 19, 23]\n",
    "program_B_experienced = [18, 16, 19, 17, 18, 16, 19, 17, 20, 18, 19, 17, 16, 18, 20, 19, 17, 18, 19, 16, 20, 19, 18, 17, 16, 19, 20, 18, 17, 19]\n",
    "\n",
    "program_C_novice = [30, 28, 29, 27, 26, 28, 29, 27, 25, 30, 28, 26, 27, 29, 30, 26, 28, 29, 25, 27, 30, 26, 28, 29, 25, 26, 27, 28, 29, 30]\n",
    "program_C_experienced = [25, 27, 28, 26, 27, 29, 26, 28, 27, 29, 25, 26, 28, 27, 29, 27, 26, 28, 29, 27, 26, 25, 29, 26, 27, 28, 29, 27, 28, 26]\n",
    "\n",
    "# Combine the data for each experience level into a single list\n",
    "novice_times = program_A_novice + program_B_novice + program_C_novice\n",
    "experienced_times = program_A_experienced + program_B_experienced + program_C_experienced\n",
    "\n",
    "# Combine the data for each program into a single list\n",
    "program_A_times = program_A_novice + program_A_experienced\n",
    "program_B_times = program_B_novice + program_B_experienced\n",
    "program_C_times = program_C_novice + program_C_experienced\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(program_A_times, program_B_times, program_C_times, novice_times, experienced_times)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74cbf2",
   "metadata": {},
   "source": [
    "## Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb05d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.833883618457257\n",
      "p-value: 2.2276723961521857e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Replace these arrays with your actual test score data for the control and experimental groups\n",
    "control_group_scores = [78, 85, 72, 90, 80, 76, 88, 83, 79, 86, 84, 81, 75, 89, 82, 77, 87, 74, 91, 73]\n",
    "experimental_group_scores = [89, 91, 83, 92, 88, 90, 86, 93, 85, 84, 87, 89, 87, 92, 90, 86, 91, 89, 88, 92]\n",
    "                                     \n",
    "# Perform the two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecdcae",
   "metadata": {},
   "source": [
    "## Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53013dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "\n",
    "# Perform the repeated measures ANOVA\n",
    "rm_anova = AnovaRM(data, 'Sales', 'Day', within=['Store'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(results.summary())\n",
    "\n",
    "# Extract the F-statistic and p-value from the ANOVA results\n",
    "f_statistic = results.anova_table['F Value'][0]\n",
    "p_value = results.anova_table['Pr > F'][0]\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the ANOVA is significant\n",
    "if p_value < 0.05:\n",
    "    # Extract the unique store names and corresponding sales data\n",
    "    store_names = data['Store'].unique()\n",
    "    store_data = [data[data['Store'] == store]['Sales'].values for store in store_names]\n",
    "    \n",
    "    # Perform Tukey's HSD test\n",
    "    tukey_results = stats.tukeyhsd(*store_data)\n",
    "\n",
    "    # Print the post-hoc test results\n",
    "    print(\"\\nPost-Hoc (Tukey's HSD) Test:\")\n",
    "    print(tukey_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
