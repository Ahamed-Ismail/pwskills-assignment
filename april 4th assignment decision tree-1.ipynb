{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac68fe4",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions.\n",
    "\n",
    "A decision tree classifier is a supervised machine learning algorithm used for both classification and regression tasks. It works by recursively splitting the dataset into subsets based on the most significant attribute at each node, ultimately forming a tree-like structure that is used to make predictions.\n",
    "\n",
    "Here's a step-by-step description of how a decision tree classifier algorithm works:\n",
    "\n",
    "1. **Initialization**: Start with the entire dataset, which consists of a set of features (attributes) and corresponding labels (class labels for classification tasks).\n",
    "\n",
    "2. **Feature Selection**: Determine the feature that best separates the data into distinct classes or values. This is typically done using a measure of impurity or information gain, such as Gini impurity or entropy. The goal is to find the feature that minimizes impurity, resulting in the most homogeneous subsets.\n",
    "\n",
    "3. **Node Creation**: Create a node in the decision tree based on the selected feature. The node represents a decision point, and it contains information about the chosen feature and its split criterion.\n",
    "\n",
    "4. **Data Splitting**: Split the data into subsets based on the values of the chosen feature. Each subset corresponds to a branch from the node. For categorical features, this is straightforward as the data is split into subsets for each category. For continuous features, the data can be split into intervals or ranges.\n",
    "\n",
    "5. **Recursion**: Recursively apply steps 2-4 to each subset created in the previous step. Continue this process until one of the stopping criteria is met, such as reaching a predefined depth limit, achieving a minimum number of samples per leaf node, or no further improvement in impurity can be gained.\n",
    "\n",
    "6. **Leaf Nodes**: When a stopping criterion is met or when a subset becomes homogeneous (i.e., all samples in the subset belong to the same class), create a leaf node. The leaf node represents the predicted class or regression value for that subset of data.\n",
    "\n",
    "7. **Tree Construction**: Continue building the tree until all nodes are either decision nodes or leaf nodes. The resulting tree structure represents the decision logic learned from the training data.\n",
    "\n",
    "8. **Prediction**: To make a prediction for a new, unseen data point, start at the root node and traverse the tree by following the appropriate branches based on the feature values of the data point. Eventually, you will reach a leaf node, and the class label associated with that leaf node is the prediction for the input data point.\n",
    "\n",
    "Key characteristics of decision tree classifiers:\n",
    "- Decision trees are interpretable, as you can visually trace the decision path.\n",
    "- They can handle both categorical and continuous features.\n",
    "- Decision trees are prone to overfitting, especially when the tree depth is not limited.\n",
    "- Techniques like pruning and using minimum sample size per leaf can help control overfitting.\n",
    "- Ensembles of decision trees, such as Random Forests and Gradient Boosted Trees, are often used to improve predictive performance and reduce overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a98eb1",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.\n",
    "\n",
    "The mathematical intuition behind decision tree classification primarily involves two key concepts: impurity measures and recursive splitting. Let's break down the mathematical intuition step by step:\n",
    "\n",
    "1. **Impurity Measures**:\n",
    "   - Decision trees use impurity measures to evaluate how \"mixed\" or impure the labels (classes) are in a given dataset or subset.\n",
    "   - Common impurity measures used in decision trees include Gini impurity and entropy (information gain). These measures quantify the uncertainty or disorder in a set of labels.\n",
    "\n",
    "2. **Gini Impurity**:\n",
    "   - Gini impurity measures the probability of incorrectly classifying a randomly chosen element if it were labeled according to the distribution of class labels in the subset.\n",
    "   - Mathematically, the Gini impurity for a subset S is calculated as follows:\n",
    "     ```\n",
    "     Gini(S) = 1 - Σ(p_i)^2\n",
    "     ```\n",
    "     Where:\n",
    "     - `p_i` is the probability of class i in the subset S.\n",
    "     - The summation goes over all classes.\n",
    "\n",
    "3. **Entropy**:\n",
    "   - Entropy measures the average amount of information (uncertainty) needed to classify an element in the subset correctly.\n",
    "   - Mathematically, the entropy for a subset S is calculated as follows:\n",
    "     ```\n",
    "     Entropy(S) = -Σ(p_i * log2(p_i))\n",
    "     ```\n",
    "     Where:\n",
    "     - `p_i` is the probability of class i in the subset S.\n",
    "     - The summation goes over all classes.\n",
    "     - The logarithm is typically taken with base 2 to measure entropy in bits.\n",
    "\n",
    "4. **Splitting Criteria**:\n",
    "   - Decision trees aim to minimize impurity. To do this, they consider various splitting criteria for each feature to determine how to divide the data into subsets.\n",
    "   - For categorical features, the tree explores all possible splits based on feature values.\n",
    "   - For continuous features, decision trees consider various thresholds to divide the data into intervals.\n",
    "\n",
    "5. **Recursive Splitting**:\n",
    "   - Starting with the entire dataset, decision trees recursively split the data based on the feature that results in the greatest reduction in impurity (or highest information gain) at each node.\n",
    "   - Reduction in impurity is calculated by comparing the impurity of the current node to the weighted impurity of the child nodes.\n",
    "\n",
    "6. **Stopping Criteria**:\n",
    "   - Decision trees continue splitting until one or more stopping criteria are met. Common stopping criteria include a maximum tree depth, a minimum number of samples per leaf, or no further impurity reduction.\n",
    "   - Stopping criteria prevent the tree from becoming overly complex and overfitting the training data.\n",
    "\n",
    "7. **Leaf Nodes**:\n",
    "   - When a stopping criterion is met or when a subset becomes pure (all samples belong to the same class), a leaf node is created.\n",
    "   - The leaf node represents the predicted class for the subset, and the decision tree construction process for that branch terminates.\n",
    "\n",
    "8. **Prediction**:\n",
    "   - To make a prediction for a new data point, the decision tree traverses the tree structure by comparing feature values to the splitting criteria at each node.\n",
    "   - The prediction is the class associated with the leaf node reached in the traversal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3721566b",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.\n",
    "\n",
    "A decision tree classifier can be used to solve a binary classification problem by creating a tree-like structure that makes decisions to classify data points into one of two classes: the positive class (Class 1) or the negative class (Class 0). Here's a step-by-step explanation of how a decision tree classifier is used for binary classification:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Collect and prepare your labeled training data. Each data point should have a set of features (attributes) and a corresponding binary label indicating whether it belongs to the positive class (1) or the negative class (0).\n",
    "\n",
    "2. **Model Training**:\n",
    "   - Fit the decision tree classifier to the training data. During training, the decision tree algorithm will automatically select features and create decision rules (splits) to divide the data into subsets based on the most informative features.\n",
    "\n",
    "3. **Tree Construction**:\n",
    "   - The decision tree construction process involves recursively selecting features and creating decision nodes. At each node, the algorithm evaluates different splitting criteria (e.g., Gini impurity or entropy) to find the feature that best separates the data into the two classes. The selected feature and split criterion are stored in the node.\n",
    "\n",
    "4. **Data Splitting**:\n",
    "   - After selecting the feature and split criterion, the data is divided into two subsets: one for which the criterion is true and one for which it is false. This process continues for each node, creating a tree structure.\n",
    "\n",
    "5. **Stopping Criteria**:\n",
    "   - The tree-building process continues until one or more stopping criteria are met. Common stopping criteria include reaching a maximum tree depth, having a minimum number of samples per leaf node, or no further reduction in impurity can be achieved.\n",
    "\n",
    "6. **Leaf Nodes**:\n",
    "   - When a stopping criterion is met, or when a subset becomes pure (all samples belong to one class), a leaf node is created. Leaf nodes do not have further splits and represent the predicted class for the corresponding subset of data.\n",
    "\n",
    "7. **Prediction**:\n",
    "   - To make a prediction for a new, unseen data point:\n",
    "     - Start at the root node of the decision tree.\n",
    "     - Traverse the tree by following the branches based on the feature values of the input data point.\n",
    "     - Continue this traversal until you reach a leaf node.\n",
    "     - The class associated with the leaf node is the predicted class for the input data point.\n",
    "\n",
    "8. **Evaluation**:\n",
    "   - Use the trained decision tree classifier to predict the class labels for the test or validation dataset.\n",
    "   - Evaluate the classifier's performance using relevant metrics such as accuracy, precision, recall, F1-score, and the receiver operating characteristic (ROC) curve.\n",
    "\n",
    "9. **Tuning and Pruning**:\n",
    "   - Depending on the performance and overfitting concerns, you may fine-tune hyperparameters (e.g., tree depth, minimum samples per leaf) and consider pruning techniques to optimize the decision tree's performance and generalization ability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3671b",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.\n",
    "\n",
    "The geometric intuition behind decision tree classification involves visualizing how the decision boundaries created by the tree divide the feature space to separate different classes. Decision trees create decision boundaries that are orthogonal to the feature axes, and these boundaries can be visualized as a series of axis-aligned splits in the feature space.\n",
    "\n",
    "Here's a step-by-step explanation of the geometric intuition behind decision tree classification and how it can be used to make predictions:\n",
    "\n",
    "1. **Binary Splits**:\n",
    "   - Decision trees make binary splits at each node. In the case of binary classification, this means that at each node, the feature space is divided into two regions: one region where the data points are classified as Class 0 (negative class), and another region where the data points are classified as Class 1 (positive class).\n",
    "\n",
    "2. **Axis-Aligned Decision Boundaries**:\n",
    "   - The splits created by decision trees are always orthogonal (perpendicular) to the feature axes. This means that the decision boundaries are aligned with one feature at a time.\n",
    "   - Each internal node of the tree corresponds to a decision boundary that is determined by a single feature and a threshold value for that feature.\n",
    "\n",
    "3. **Recursive Splitting**:\n",
    "   - The decision tree construction process is recursive, where the data is divided into subsets based on feature values at each node.\n",
    "   - At each level of the tree, the decision boundary is created, dividing the feature space into two regions.\n",
    "   - This process continues until the stopping criteria are met or until the data in a subset becomes pure (i.e., all samples belong to one class).\n",
    "\n",
    "4. **Leaf Nodes**:\n",
    "   - When a stopping criterion is met or when a subset becomes pure, a leaf node is created. Leaf nodes represent the final classification decision for the data points within that region.\n",
    "   - The class label associated with a leaf node is the majority class of the data points in that region.\n",
    "\n",
    "5. **Decision Path**:\n",
    "   - To make a prediction for a new data point, you start at the root of the decision tree and follow the decision path by comparing the feature values of the data point to the feature thresholds at each node.\n",
    "   - At each node, you choose the branch that corresponds to the feature value of the data point. This process continues until you reach a leaf node.\n",
    "\n",
    "6. **Prediction**:\n",
    "   - The class label associated with the leaf node reached in the decision path is the predicted class for the input data point.\n",
    "   - This prediction is based on the decision boundaries defined by the tree, and it assigns the data point to one of the two classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e813e",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.\n",
    "\n",
    "A confusion matrix is a table that is used to evaluate the performance of a classification model, especially in machine learning and statistics. It provides a summary of the model's predictions compared to the actual outcomes in a classification problem. The confusion matrix is particularly useful when dealing with binary classification problems (two classes) but can also be extended to multi-class problems (more than two classes).\n",
    "\n",
    "A confusion matrix consists of four key metrics or values:\n",
    "\n",
    "1. True Positives (TP): These are the cases where the model correctly predicted the positive class (class 1) when the actual class is indeed positive.\n",
    "\n",
    "2. True Negatives (TN): These are the cases where the model correctly predicted the negative class (class 0) when the actual class is indeed negative.\n",
    "\n",
    "3. False Positives (FP): Also known as Type I errors, these are the cases where the model incorrectly predicted the positive class when the actual class is negative. In other words, the model produced a false alarm.\n",
    "\n",
    "4. False Negatives (FN): Also known as Type II errors, these are the cases where the model incorrectly predicted the negative class when the actual class is positive. In other words, the model missed identifying positive instances.\n",
    "\n",
    "Here's a visual representation of a confusion matrix:\n",
    "\n",
    "```\n",
    "          Actual Positive     Actual Negative\n",
    "Predicted\n",
    "Positive    True Positives (TP)    False Positives (FP)\n",
    "Negative    False Negatives (FN)   True Negatives (TN)\n",
    "```\n",
    "\n",
    "Now, let's discuss how the confusion matrix can be used to evaluate the performance of a classification model:\n",
    "\n",
    "1. **Accuracy:** Accuracy is a common metric that measures the overall correctness of the model's predictions. It is calculated as (TP + TN) / (TP + TN + FP + FN). However, accuracy alone may not be suitable for imbalanced datasets where one class significantly outweighs the other.\n",
    "\n",
    "2. **Precision:** Precision measures the accuracy of positive predictions. It is calculated as TP / (TP + FP). It helps you understand how many of the predicted positive cases were actually correct.\n",
    "\n",
    "3. **Recall (Sensitivity or True Positive Rate):** Recall measures the model's ability to identify all positive instances. It is calculated as TP / (TP + FN). It helps you understand how many of the actual positive cases were correctly predicted.\n",
    "\n",
    "4. **Specificity (True Negative Rate):** Specificity measures the model's ability to identify all negative instances. It is calculated as TN / (TN + FP). It helps you understand how many of the actual negative cases were correctly predicted.\n",
    "\n",
    "5. **F1-Score:** The F1-score is the harmonic mean of precision and recall, which balances the trade-off between these two metrics. It is calculated as 2 * (Precision * Recall) / (Precision + Recall).\n",
    "\n",
    "6. **ROC Curve and AUC:** The Receiver Operating Characteristic (ROC) curve is a graphical representation of the model's performance across different thresholds. The Area Under the ROC Curve (AUC) provides a single scalar value that summarizes the model's ability to distinguish between classes. A higher AUC indicates better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8cf0d",
   "metadata": {},
   "source": [
    "## Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.\n",
    "\n",
    "Sure, let's start with an example of a confusion matrix and then calculate the precision, recall, and F1 score from it.\n",
    "\n",
    "Suppose we have a binary classification problem where we are trying to distinguish between whether an email is spam (positive class) or not spam (negative class). After running our classification model on a test dataset, we obtain the following confusion matrix:\n",
    "\n",
    "```\n",
    "          Actual Not Spam     Actual Spam\n",
    "Predicted\n",
    "Not Spam      875               20\n",
    "Spam          30                75\n",
    "```\n",
    "\n",
    "In this confusion matrix:\n",
    "\n",
    "- True Positives (TP) = 75: The model correctly predicted 75 emails as spam when they were actually spam.\n",
    "- True Negatives (TN) = 875: The model correctly predicted 875 emails as not spam when they were actually not spam.\n",
    "- False Positives (FP) = 20: The model incorrectly predicted 20 emails as spam when they were not spam.\n",
    "- False Negatives (FN) = 30: The model incorrectly predicted 30 emails as not spam when they were actually spam.\n",
    "\n",
    "Now, let's calculate precision, recall, and F1 score:\n",
    "\n",
    "1. **Precision:** Precision measures the accuracy of positive predictions, i.e., the ability of the model to correctly identify spam emails.\n",
    "\n",
    "   Precision = TP / (TP + FP) = 75 / (75 + 20) = 75 / 95 ≈ 0.7895 (rounded to 4 decimal places)\n",
    "\n",
    "   So, the precision for this model is approximately 0.7895.\n",
    "\n",
    "2. **Recall (Sensitivity):** Recall measures the model's ability to identify all actual spam emails correctly.\n",
    "\n",
    "   Recall = TP / (TP + FN) = 75 / (75 + 30) = 75 / 105 ≈ 0.7143 (rounded to 4 decimal places)\n",
    "\n",
    "   So, the recall for this model is approximately 0.7143.\n",
    "\n",
    "3. **F1-Score:** The F1-score is the harmonic mean of precision and recall, which balances the trade-off between these two metrics.\n",
    "\n",
    "   F1-Score = 2 * (Precision * Recall) / (Precision + Recall) = 2 * (0.7895 * 0.7143) / (0.7895 + 0.7143) ≈ 0.7500 (rounded to 4 decimal places)\n",
    "\n",
    "   So, the F1-score for this model is approximately 0.7500.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c14578",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.\n",
    "\n",
    "Choosing an appropriate evaluation metric for a classification problem is crucial because it determines how you assess the performance of your model, and the choice should align with the specific goals and requirements of your problem. Different metrics provide different insights into a model's performance, and selecting the right one ensures that you measure what matters most in your application. Here's why it's important and how it can be done:\n",
    "\n",
    "**1. Aligning with Business Objectives:**\n",
    "   - The choice of evaluation metric should reflect the ultimate goals of your project. For example, in a medical diagnosis application, correctly identifying patients with a disease (high recall) might be more important than minimizing false alarms (low precision). In contrast, in an email spam filter, precision might be more critical to avoid incorrectly classifying legitimate emails as spam.\n",
    "\n",
    "**2. Handling Class Imbalance:**\n",
    "   - Class imbalance occurs when one class has significantly more samples than the other. In such cases, accuracy alone can be misleading. Metrics like precision, recall, F1-score, or area under the ROC curve (AUC) provide a more balanced view of performance by accounting for false positives and false negatives.\n",
    "\n",
    "**3. Trade-offs:**\n",
    "   - Different metrics emphasize different trade-offs between precision and recall. For example, if you increase the decision threshold of your classifier to improve precision, recall may decrease and vice versa. Understanding these trade-offs is crucial for making informed decisions.\n",
    "\n",
    "**4. Context Sensitivity:**\n",
    "   - Consider the context of your application. For instance, in a legal system for criminal identification, a false negative (missing a criminal) could have severe consequences, so recall might be prioritized. In contrast, for a recommendation system, a false negative (missing a relevant item) might not be as critical, and precision could be more important.\n",
    "\n",
    "**5. Dataset and Problem Characteristics:**\n",
    "   - The nature of your dataset and problem can influence metric choice. For example, in multi-class problems, you might use metrics like multi-class accuracy, macro-averaged F1-score, or confusion matrices to understand class-specific performance.\n",
    "\n",
    "**6. Model Comparison:**\n",
    "   - When comparing multiple models or algorithms, using a consistent evaluation metric is essential for fair comparisons. You should select a metric that aligns with your primary goal while still providing a well-rounded assessment.\n",
    "\n",
    "**7. Visualization and Interpretation:**\n",
    "   - Different metrics can be visualized in various ways. For example, ROC curves help visualize the trade-off between true positive rate and false positive rate. Visualizations can aid in better understanding model performance.\n",
    "\n",
    "**8. Cross-validation and Validation Sets:**\n",
    "   - When training and tuning models, it's common practice to use cross-validation or a validation set to assess their performance. During this process, you can experiment with different metrics and choose the one that best suits your needs.\n",
    "\n",
    "**9. Consideration of Costs:**\n",
    "   - Some errors may have higher costs associated with them. For instance, in a credit fraud detection system, missing a fraudulent transaction may result in significant financial losses. Understanding these costs can guide metric selection.\n",
    "\n",
    "To choose an appropriate evaluation metric for a classification problem, follow these steps:\n",
    "\n",
    "1. **Understand the Problem**: Gain a deep understanding of your problem, its context, and the potential consequences of different types of errors.\n",
    "\n",
    "2. **Define Success**: Clearly define what success means for your specific task. What outcomes are most important to you or your stakeholders?\n",
    "\n",
    "3. **Consider Class Distribution**: Analyze the class distribution to determine if your problem is imbalanced, which may require different metrics.\n",
    "\n",
    "4. **Review Available Metrics**: Familiarize yourself with various classification metrics (e.g., accuracy, precision, recall, F1-score, AUC-ROC, AUC-PR) and their trade-offs.\n",
    "\n",
    "5. **Experiment and Iterate**: Experiment with different metrics during model development and fine-tuning. Iterate based on what works best for your problem.\n",
    "\n",
    "6. **Visualize and Interpret**: Use visualization tools and confusion matrices to gain insights into model performance and to make informed decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0863452",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why.\n",
    "\n",
    "Consider a medical diagnostic scenario where the classification problem involves identifying patients with a rare and potentially life-threatening disease, such as a certain type of cancer. In this case, precision can be the most important metric, and here's why:\n",
    "\n",
    "**Example: Early Detection of Rare Cancer**\n",
    "\n",
    "In a medical context, precision measures the ability of a diagnostic test or classification model to correctly identify individuals who actually have the disease (true positives) while minimizing false positives. Let's break down why precision is crucial in this scenario:\n",
    "\n",
    "1. **High Stakes**: Missing a diagnosis of this rare cancer can have severe consequences, including delayed treatment and potentially fatal outcomes. Therefore, false negatives (missed cases) should be minimized.\n",
    "\n",
    "2. **Treatment and Resources**: Treating cancer can be invasive and expensive. Unnecessary treatments can harm patients physically and financially. High precision helps ensure that only those truly at risk receive further testing and treatment.\n",
    "\n",
    "3. **Patient Anxiety**: False positive results can cause unnecessary anxiety and stress for patients. Reducing false positives through high precision helps alleviate this emotional burden.\n",
    "\n",
    "4. **Medical Resources**: Healthcare resources, such as specialized tests and medical professionals, are often limited. Maximizing precision ensures that these resources are allocated to those who need them most.\n",
    "\n",
    "5. **Legal and Ethical Considerations**: In some cases, medical professionals can face legal and ethical consequences for incorrect diagnoses. High precision reduces the risk of wrongful diagnoses and associated liabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc4cf3",
   "metadata": {},
   "source": [
    "##  Q9. Provide an example of a classification problem where recall is the most important metric, and explain why.\n",
    "\n",
    "Consider a security application where the classification problem involves detecting malware in computer systems. In this scenario, recall can be the most important metric, and here's why:\n",
    "\n",
    "**Example: Malware Detection**\n",
    "\n",
    "In the context of malware detection, recall measures the ability of a security system or antivirus software to correctly identify all instances of malware (true positives) while minimizing false negatives (missed cases). Here's why recall is crucial in this scenario:\n",
    "\n",
    "1. **Security and Data Protection**: Malware, such as viruses, ransomware, and spyware, can cause significant damage to computer systems and compromise sensitive data. Missing even a single instance of malware can lead to severe security breaches.\n",
    "\n",
    "2. **Preventing Data Loss**: Malware attacks can result in data loss or data theft, with potentially serious consequences for individuals and organizations. High recall helps ensure that all malware is detected and mitigated, reducing the risk of data loss.\n",
    "\n",
    "3. **Network and System Disruption**: Malware can disrupt the normal functioning of computer networks and systems, leading to downtime and financial losses. High recall is critical for promptly identifying and neutralizing malware to minimize disruption.\n",
    "\n",
    "4. **Mitigating Malware Spread**: Some malware is designed to propagate itself to other systems on a network. Detecting and removing malware with high recall can prevent its spread to other vulnerable systems.\n",
    "\n",
    "5. **Legal and Compliance Requirements**: In many industries, there are legal and compliance requirements that mandate the thorough detection and prevention of malware. High recall helps organizations meet these obligations.\n",
    "\n",
    "6. **Reputation and Trust**: Organizations that fail to detect and prevent malware effectively may suffer damage to their reputation and the trust of their customers and clients. High recall contributes to maintaining trust in cybersecurity measures.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
